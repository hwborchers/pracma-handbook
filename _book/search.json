[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pracma Handbook",
    "section": "",
    "text": "Preface\nDESCRIPTION file\nPackage: pracma\nType: Package\nVersion: 2.1.6\nDate: 2018-08-30\nTitle: Practical Numerical Math Functions\nAuthors@R: person(\"Hans W.\", \"Borchers\", \n                  email=\"hwborchers@googlemail.com\", \n                  role=c(\"aut\", \"cre\"))\nDepends: R (&gt;= 3.1.0)\nImports: graphics, grDevices, stats, utils\nSuggests: quadprog\nDescription:\n    Provides a large number of functions from numerical analysis and\n    linear algebra, numerical optimization, differential equations,\n    time series, plus some well-known special mathematical functions.\n    Uses 'MATLAB' function names where appropriate to simplify porting.\nLicense: GPL (&gt;= 3)\nByteCompile: true\nLazyData: yes"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "specfun.html#introduction",
    "href": "specfun.html#introduction",
    "title": "2  Special Functions",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nThe pracma package contains many special functions from Mathematics and Mathematical Physics. Some of them are also provided in other R packages, others may not. They are compiled in pracma as they appear to be a basic ingredient in all kinds of scientific computations.\nAnother source of special functions for R is the gsl package, providing a wrapper for some of the functions of the Gnu Scientific Library (GSL). Among the functions available are Airy functions, Bessel functions, elliptic and exponential functions, hypergeometric functions, Legendre functions, or Digamma functions, to list only a few.\nAiry and Bessel functions, for real and complex numbers, are computed with high accuracy in package Bessel. Weierstrass and Jacobi elliptic (and related) functions are available in elliptic. Gauss’ Hypergeometric function is implemented in the hypergeo package."
  },
  {
    "objectID": "specfun.html#trigonometric-and-hyperbolic-functions",
    "href": "specfun.html#trigonometric-and-hyperbolic-functions",
    "title": "2  Special Functions",
    "section": "2.2 Trigonometric and hyperbolic Functions",
    "text": "2.2 Trigonometric and hyperbolic Functions\nBase R contains the usual trigonometric functions sin, cos, and tan and their inverses asin, acos, and atan. Also, atan2 is here, calculating the angle between the x-axis and the vector (x, y) in a more precise way (i.e., atan2(x,y) = atan(y/x)). These functions accept complex values as input.\n\n2.2.1 More trigonometric functions\nThe usual trigonometric cotangens, cosecans, and secans functions and their inverses are not available in Base R. In pracma they are computed through the other well known sine, cosine, and tangens functions.\ncot(z)      acot(z)\ncsc(z)      acsc(z)\nsec(z)      asec(z)\nLike the trigonometric functions in R they accept complex numbers as input.\n\n\n2.2.2 More hyperbolic functions\nR provides the hyperbolic sine, cosine, and tangens functions (and their inverses), pracma adds the cotangens, cosecans, and secans functions and their inverses, computed through the other hyperbolic sine, cosine, and tangens functions.\ncoth(z)     acoth(z)\ncsch(z)     acsch(z)\nsech(z)     asech(z)\n\n\n2.2.3 Degrees as input\nThe usual trigonometric functions such as the sine and cosine functions sin, cos, etc., are included with R and utilize the standard C libraries. pracma knows all these functions with an appended d, indicating they take degrees instead of radians as input.\n\nlibrary(pracma)\nsin(pi); sind(180)\n\n[1] 1.224647e-16\n\n\n[1] 0\n\n\nThese functions try to be more exact at multiples of pi or pi/2. Internally thay use the functions sinpi and cospi that are part of Base R and the standard C libraries, but may be unknown to many users.\nTrigonometric functions with degree inputs provided by pracma are\nsind(x)     asind(x)    secd(x)     atan2d(x1, x2)\ncosd(x)     acosd(x)    cscd(x)\ntand(x)     atand(x)    asecd(x)\ncotd(x)     acotd(x)    acscd(x)\nThe reason all these (not really necessary) functions are present in pracma is mostly that they are part of MATLAB under the same name."
  },
  {
    "objectID": "specfun.html#gamma-functions",
    "href": "specfun.html#gamma-functions",
    "title": "2  Special Functions",
    "section": "2.3 Gamma functions",
    "text": "2.3 Gamma functions\nThe functions gamma and lgamma in R return the gamma function and the natural logarithm of the absolute value of the gamma function for real input (except 0 and negative integers). digamma and trigamma return the first and second derivatives of the logarithm of the gamma function.\n\n2.3.1 Complex Gamma function\nIn pracma, gammaz computes the complex gamma function, valid in the entire complex plane, using the Lanczos series approximation. Accuracy is assumed to be 13 significant digits. As an example, see Euler’s reflection formula:\n\nz &lt;- 1 + 1i\ngammaz(1-z) * gammaz(z)  # == pi/sin(pi*z)\n\n[1] 0+0.2720291i\n\n\n\n\n2.3.2 Incomplete Gamma functions\nThere are also the lower, upper and regularized ‘incomplete gamma’ functions, defined for real values alone. \\[\n  γ(x, a) = \\int_0^x e^{-t} \\, t^{a-1} \\, dt\n\\] and \\[\n  Γ(x, a) = \\int_x^{∞} e^{-t} \\, t^{a-1} \\, dt\n\\] The regularized incomplete gamma function is \\(\\gamma(x,a)/\\Gamma(a)\\). All three values will be returned by gammainc, while the function incgam calculates the upper incomplete gamma function (with higher accuracy).\n\ngammainc(1.5, 2.0)\n\n   lowinc    uppinc    reginc \n0.4421746 0.5578254 0.4421746 \n\n\nThese values could be retrieved from incgam(1.5, 2.0) alone."
  },
  {
    "objectID": "specfun.html#lambert-w-function",
    "href": "specfun.html#lambert-w-function",
    "title": "2  Special Functions",
    "section": "2.4 Lambert W function",
    "text": "2.4 Lambert W function\nThe Lambert W function is given as the inverse of \\(f(x) = x e^x\\), for positive \\(x\\), and therefore lambertW(0) = 0. Its positive branch for \\(x &gt;= 0\\) is defined as lambertWp. In the intervall \\((-1/e, 0]\\) there is a second, negative branch called with lambertWn.\n\n\n\n\n\nThe value at \\(x = 1\\) is named (Gauss’) omega constant and has a value of\n\nomega = pracma::lambertWp(1.0)\nprint(omega, digits = 16)\n\n[1] 0.5671432904097838\n\n\nThe Lambert W function in pracma is computed through “Halley’s method” and is quite fast and accurate."
  },
  {
    "objectID": "specfun.html#elliptic-integrals",
    "href": "specfun.html#elliptic-integrals",
    "title": "2  Special Functions",
    "section": "2.5 Elliptic integrals",
    "text": "2.5 Elliptic integrals\nElliptic integrals arose first in connection with the problem of computing the arc length of ellipses and more general conic sections.\n\n2.5.1 Complete elliptic integrals\nComplete elliptic integrals of the first and second kind, often named K and E, are defined as \\[\n  K(x) = \\int_0^{\\pi/2} \\frac{dt}{\\sqrt{1 - x^2\\,\\sin^2(t)}}\n\\] \\[\n  E(x) = \\int_0^{\\pi/2} \\sqrt{1 - k^2\\,\\sin^2(t)} dt\n\\]\nThe function name in pracma is ellipke. It returns a list with two components, k the value for the first kind, e the value for the second kind.\n\ne = sqrt(1 - 0.5^2/1^2)  # ellipsis with axes 1, 1/2\nellipke(e)\n\n$k\n[1] 2.441342\n\n$e\n[1] 1.131469\n\n\nAn ellipsis with semi-major axis \\(a\\) and semi-minor \\(b\\), and thus eccentricity \\(e = \\sqrt{1 - b^2/a^2}\\), has a total circumference of \\(U = 4 a E(e)\\).\n\ncat(\"circumference(1.0, 0.5) =\", 4 * 1.0 * ellipke(e)$e)\n\ncircumference(1.0, 0.5) = 4.525876\n\n\n\n\n2.5.2 Jacobi elliptic integrals\nJacobi elliptic functions are defined as inverses of the incomplete elliptic integral of the first kind. If \\[\n  u = \\int_0^x \\frac{dt}{\\sqrt{1 - m\\,\\sin^2(t)}}\n\\] then the elliptic sine sn and cosine cn functions are given by \\[\n  sn(u) = \\sin(x); cn(u) = \\cos(x)\n\\] and the delta amplitude dn as \\[\n  dn(u) = \\sqrt{1 - m\\,\\sin^2(x)}\n\\]\nellipj computes the Jacobi elliptic integrals sn, cn, and dn in one go.\nu &lt;- c(0, 1, 2, 3, 4)      # use (u[i], m[i])\nm &lt;- 0.5\n( je = ellipj(u, m) )\n## $sn  0.000000  0.803002  0.994662  0.630029 -0.285778\n## $cn  1.000000  0.595977 -0.103184 -0.776572 -0.958296\n## $dn  1.000000  0.823161  0.710861  0.895283  0.979370\nThe following relations are always valid: \\(sn^2 + cn^2 = 1\\) and \\(dn^2 + m \\cdot sn^2 = 1\\)."
  },
  {
    "objectID": "specfun.html#exponential-and-logarithmic-integral",
    "href": "specfun.html#exponential-and-logarithmic-integral",
    "title": "2  Special Functions",
    "section": "2.6 Exponential and logarithmic integral",
    "text": "2.6 Exponential and logarithmic integral\n\n2.6.1 Exponential integrals\nThe exponential integral functions \\(E1\\) and \\(Ei\\) are for real \\(x &gt; 0\\) defined as \\[\n  E1(x) = \\int_x^\\infty \\frac{e^{-t}}{t} \\, dt; \\qquad\n  Ei(x) = \\int_{-\\infty}^x \\frac{e^t}{t} \\, dt;\n\\]\nBoth can be extended to the complex plane by analytic continuation. The relationship between them is \\(Ei(x) = -E1(-x) - i\\pi\\).\nThese functions are implemented as expint_E1 (with ‘alias’ expint) and expint_Ei.\n\n\n2.6.2 Logarithmic integral\nThe logarithmic integral \\(li\\) – li in pracma – is defined for \\(x &gt; 0\\) as \\[\n  li(x) = \\int_0^x \\frac{dt}{\\log(t)}\n\\] while the Eulerian logarithmic integral \\(Li\\) is \\(Li(x) = li(x) - li(2)\\). \\(Li\\) approximates the prime number function \\(\\pi(n)\\), that is the number of primes below or equal to \\(n\\).\nTable: Estimation of prime numbers\n\n\n\nn\nno. primes\nLi estimate\naccuracy\n\n\n\n\n1\n5\n4\n0.2500000000\n\n\n2\n29\n25\n0.1600000000\n\n\n3\n177\n168\n0.0535714286\n\n\n4\n1245\n1229\n0.0130187144\n\n\n5\n9629\n9592\n0.0038573812\n\n\n6\n78627\n78498\n0.0016433540\n\n\n7\n664917\n664579\n0.0005085927\n\n\n8\n5762208\n5761455\n0.0001306962\n\n\n9\n50849234\n50847534\n0.0000334333\n\n\n\nFor generating this table we used the following functions:\nestimPi &lt;- function(n) round(Re(li(n) - li(2))) # estimated number of primes\nprimesPi &lt;- function(n) length(primes(n))       # true number of primes &lt;= n\ni.e., the logarithmic integral and the primes function from pracma."
  },
  {
    "objectID": "specfun.html#trigonometric-integrals",
    "href": "specfun.html#trigonometric-integrals",
    "title": "2  Special Functions",
    "section": "2.7 Trigonometric integrals",
    "text": "2.7 Trigonometric integrals\n\n2.7.1 Sine and Cosine integrals\nThe sine and cosine integrals are defined with the sinc function as integrand. \\[\n  Si(x) = \\int_0^x \\frac{\\sin(t)}{t} dt\n\\] resp. as \\[\n  Ci(x) = - \\int_x^\\infty \\frac{\\cos(t)}{t} dt = γ + \\log(x) + \\int_0^x \\frac{\\cos(t)-1}{t} dt\n\\] (The value Ci(x) is not correct, it should be Ci(x)+pi*i, only the real part is returned.)\nThe spiral formed by a parametric plot of Si and Ci is known as Nielsen’s spiral and is closely related to the Cornu spiral, see below.\n\n\n\n\n\nThere are also hyperbolic sine Shi and cosine Chi integrals, with e.g. \\(\\sinh\\) instead of \\(\\sin\\) in the definition above. There is a relation \\({\\displaystyle \\operatorname {Si} (ix)=i\\operatorname {Shi} (x).}\\), which does not work here as Si accepts only real values.\n\n\n2.7.2 Fresnel integrals\nThe ‘normalized’ Fresnel integrals \\(S\\) and \\(C\\) are defined as \\[\n  S(x) = \\int_0^x \\sin(π/2 \\, t^2) dt\n\\] and \\[\n  C(x) = \\int_0^x \\cos(π/2 \\, t^2) dt\n\\]\nThe integral \\(\\int_0^x \\sin(t^2) dt\\) can then be calculated as \\(\\sqrt{\\pi/2}\\,S(\\sqrt{2/\\pi}\\,x)\\).\nThey are used in optics and are closely related to the error function. In pracma they are available as fresnelS resp. fresnelC. Plotting one against the other will display the well-known Cornu (or Euler) spiral."
  },
  {
    "objectID": "specfun.html#eta-and-zeta-functions",
    "href": "specfun.html#eta-and-zeta-functions",
    "title": "2  Special Functions",
    "section": "2.8 Eta and zeta functions",
    "text": "2.8 Eta and zeta functions\n\n2.8.1 Riemann’s zeta function\nThe celebrated Riemann zeta function is defined as \\[\n  \\zeta(s) = \\sum_{n=1}^\\infty \\frac{1}{n^s}\n\\] which is converging for all complex numbers \\(s\\) with \\(Re(s) &gt; 1\\). The function can be extended to the complex plane by analytic continuation. It has a pole in \\(s = 1\\) and so-called trivial zeros in \\(-2, -4, -6, ...\\).\nThe pracma function zeta computes Riemann’s zeta function in the entire complex plane.\nThe Riemann conjecture says that the only non-trivial zeros of the zeta function all lie on the critical line \\(Re(s) = \\frac{1}{2}\\). Let’ calculate the first one (of the billions that have been found) applying the Newton-Raphson method.\n\nf = function(x) abs(zeta(0.5+x*1i))\nz1 = newtonRaphson(f, 12, maxiter = 1000, tol = 1e-16)$root\nprint(z1, digits=16)\n\n[1] 14.13472514173372\n\n\nthe true value being \\(z1 = 14.\\,134\\,725\\,141\\,734\\,693\\,790\\,...\\).\n\n\n\n\n\nThis plot also suggests that there may be very many zeros on the critical line.\n\n\n2.8.2 Dirichlet’s eta function\nThe Dirichlet eta function, aka ‘alternating zeta function’, is for complex numbers \\(z\\) with \\(Re(z) &gt; 0\\) defined as \\[\n  \\eta(s) = \\sum_{n=1}^\\infty \\frac{(-1)^{n-1}}{n^s} = \\frac{1}{1^s} - \\frac{1}{2^s} + \\frac{1}{3^s} - \\frac{1}{4^s} +- ...\n\\]\nThe following relation holds: \\(\\eta(s) = (1 - 2^{1-s}) \\cdot \\zeta(s)\\). As an alternating series it is easier to calculate precisely, and is utilized here to find values for the zeta function, too.\nWe will compute Apery’s constant zeta(3) with the help of eta, applying the “alternating series acceleration” of Cohen et al., implemented in pracma’s sumalt function.\n\neta_alt = function(k) (-1)^k / (k+1)^3  # starts with k=0\napery = 4/3 * sumalt(eta_alt, 21)\n\nprint(apery, digits = 16)\n\n[1] 1.202056903159594\n\n\nThe true value of Apery’s constant is \\(1.20205690315959428...\\). It was long unknown whether this number is irrational, it is still unknown whether it is a transcendental number."
  },
  {
    "objectID": "rootfinding.html#univariate-roots",
    "href": "rootfinding.html#univariate-roots",
    "title": "5  Root Finding",
    "section": "5.1 Univariate roots",
    "text": "5.1 Univariate roots\n\n5.1.1 Brent-Dekker\nThe basic routine for finding roots of univariate (i.e., one-dimensional) functions in Base R is uniroot which realizes the well-known Brent-Dekker method (implemented in C). It is an iterative state-of-the-art algorithm that combines bisection and quadratic interpolation.\nThe user should be aware of the following restriction:\n\nThe functions needs to have different sign at the end of the interval, otherwise an error will be thrown.\nIf there is more than one root in the interval, Brent-Dekker will only find one of them, which one is undetermined.\nZeros where the function just touches the x-axis without crossing it, cannot be found with Brent-Dekker or similar approaches.\n\nNOTE: The default tolerance in uniroot is too weak, we would recommend to always set tol = 1e-08 at least.\nIn ‘pracma’, two variants of Brent-Dekker are implemented in the functions brentDekker (alias brent) resp. fzero. brentDekker requires an interval to search in while fzero asks for an ‘initial guess’. That may help to avoid zeros you are not interested in.\nBoth are kind of “demo” implementations and are not really recommended.\n\nf6  &lt;- function(x) (x-1)*exp(-9*x) + x^9\nbrentDekker(f6, -1.4, 1.0)\n\n$root\n[1] 0.5367417\n\n$f.root\n[1] 4.844215e-16\n\n$f.calls\n[1] 15\n\n$estim.prec\n[1] 1.010156e-09\n\n\n\n\n5.1.2 Ridders’ method\nWhat is really recommended is Ridders’ method, available in ‘pracma’ through the ridders function. This routine combines a ‘regula-falsi’ approach with successively approximating the function through exponentials. riddersis fast (faster than uniroot, though written in pure R).\n\nridders(f6, -1.4, 1.0, tol= 1e-08)\n\n$root\n[1] 0.5367417\n\n$f.root\n[1] -6.938894e-18\n\n$niter\n[1] 18\n\n$estim.prec\n[1] 9.026113e-14\n\n\nThe Numerical Recipes state explicitely: “Ridders’ root finding method is a powerful variant of ‘regula falsi’ (and ‘false position’). In reliability and speed, this method is competitive with Brent-Dekker and similar approaches.”\n\n\n5.1.3 Bisection and more\nThere are three more “demo implementations” – bisect, secant, and regulaFalsi – that do exactly what their names suggest. The user is invited to look at the code; especially bisect is simple and quite accurate.\n“Regula Falsi” is a combination of the Bisection and Secant methods and will most of the time give better results than both of them.\n\n\n5.1.4 Newton-Raphson, Haley\nBrent-Dekker and similar methods rely on the fact that the function has different signs at the ends of the interval (and thus on the “intermediate value theorem” of mathematical analysis). They are not working for functions that barely touch the x-axis. In this case, Newton’s method (historically correct it should be called “Simpson’s method”) may be appropriate.\nNewton’s method (aka the Newton-Raphson method) follows the gradient of the function in direction to the x-axis. If the function is (continuously) differentiable and the starting point has been chosen near enough to the root, it will find the root very fast, but it can also be lead us far away if this starting point is not chosen carefully.\nIn ‘pracma’ Newton’s/Simpson’s method is implemented as newtonRaphson with alias newton.\n\nf &lt;- function(x) sin(x)^2\nnewtonRaphson(f, 2.0)\n\n$root\n[1] 3.141593\n\n$f.root\n[1] 3.414839e-17\n\n$niter\n[1] 24\n\n$estim.prec\n[1] 5.843663e-09"
  },
  {
    "objectID": "rootfinding.html#special-aspects",
    "href": "rootfinding.html#special-aspects",
    "title": "5  Root Finding",
    "section": "5.2 Special aspects",
    "text": "5.2 Special aspects\n\n5.2.1 Quadratic roots\nQuadratic (and higher-order roots) roots are zeros where the function just touches the x-axis without crossing it. Therefore, Brent-Dekker and similar approaches cannot be applied.\nIn such cases, Newton’s method may be your best choice, but a reliable starting point is to be known. The findzeros routine discussed in the following section may be a good way to find such a value.\n\nfab &lt;- function(x, a, b) x^a - b\nnewton(fab, 1.0, a = 100, b = 2)\n\n$root\n[1] 1.006956\n\n$f.root\n[1] 1.474376e-13\n\n$niter\n[1] 5\n\n$estim.prec\n[1] 3.34926e-09\n\n\nIt computes the a-th root of b, here the 100th root of 2.0. Be careful with the input values (e.g., \\(b &gt; 0\\)).\n\n\n5.2.2 Find all roots\nWe have seen that root finding methods stop after having found a first zero in a given interval. uniroot.all in package ‘rootsolve’ finds all simple roots, but fails to find quadratic and higher-order roots (where the function does not cross the x-axis).\nHere the function findzeros comes to rescue: It finds all roots that at least are a certain ‘tolerance’ apart – by splitting the interval in smaller intervals and applying a combination of Brent-Dekker and Newton’s method.\n\nf &lt;- function(x) x * sin(pi*x)\nfindzeros(f, -2, 2)\n\n[1] -2 -1  0  1  2\n\n\nIf the function values at endpoints of a subinterval are both positive or negative, the minimum or maximum will be determined and checked for a possible zero. The endpoints will be tested separately.\n\n\n5.2.3 High-accuracy roots\nSometimes it is necessary to determine a root with high accuracy. Take the test function f12 that is extremely flat around the root between 1 and 2.\n\nf12 &lt;- function(x)\n            log(x) + x^2/(2*exp(1)) - 2 * x/sqrt(exp(1)) + 1\n\nfplot(f12, c(1.0, 2.5))\nabline(h = 0.0, lty = 2)\n\n\n\n\nDifferent root finders will give different results like\nuniroot        |  1.6487 07674  |  tol = 1e-15 used for all\nbisect         |  1.6487 07057  |  \nregulaFalsi    |  1.6487 11081  |  \nridders        |  1.6487 13958  |  \nbrentDekker    |  1.6487 37933  |  \nfzero          |  1.6487 13285  |  starting point 2.2\nnewtonRaphson  |  1.6487 09082  |  with exact derivative\n\nridders+Rmpfr  |  1.6487 21270  |  prec = 128 bits\nTRUE value     |  1.6487 21271  |  sqrt(exp(1))\nInstead we will use multiple-precision arithmetic with the ‘Rmpfr’ package. ridders is compatible with “big floats”, but we need to strengthen our function f12 to correctly handle multiple precision numbers.\n\nm1 &lt;- Rmpfr::mpfr(1.0, 128)\nf12a &lt;- function(x)\n            log(x) + x^2/(2*exp(m1)) - 2 * x/sqrt(exp(m1)) + 1\nridders(f12a, 1, 3.4)$root\n\n1 'mpfr' number of precision  128   bits \n[1] 1.648721270699944708468219129114373800688\n\n\nWe can see in the table above that now we get the result accurate up to \\(10^{-10}\\) (or ten digits).\n\n\n5.2.4 Roots as fixed points\nTO BE DONE"
  },
  {
    "objectID": "rootfinding.html#complex-roots",
    "href": "rootfinding.html#complex-roots",
    "title": "5  Root Finding",
    "section": "5.3 Complex roots",
    "text": "5.3 Complex roots\nDetermining roots of complex functions cannot be done with the functions presented above. Two alternatives, both unsatisfying but sometimes helpful, are:\n\nGiven a function \\(f: \\mathbb{C} \\to \\mathbb{C}\\), it can be redefined as a function \\(F: \\mathbb{R}^2 \\to \\mathbb{R}^2\\) by splitting it into real and imaginary parts. Then a 2-dimensional version of Newton’s method can be applied, see below the section on “Multivariate function roots”.\nOne can instead look at the function \\(F(x, y) = |f(x + iy)|\\) and try to identify the minima where \\(F(x,y) = 0\\), applying an optimization solver (with appropriate starting points).\n\n‘pracma’ contains two routines to find roots of complex functions (of one variable), Mullers root finding method and Laguerre’s method for finding roots of complex polynomials.\n\n5.3.1 Muller’s method\nMuller’s root finding method, similar to the secant method, uses a parabola through three points for approximating the curve. It needs three points that should enclose the assumed root.\nLet’s calculate the first zero of Riemann’s Zeta function on the “critical line” (which is \\(z0 = 14.13472514173469379...\\)).\n\nfz &lt;- pracma::zeta\n\nz0 &lt;-muller(fz, 0.25+10i, 0.75+10i, 15i)\nprint(z0$root, digits = 16)\n\n[1] 0.5+14.13472514173469i\n\n\nWith Muller’s method one can search for complex zeros by systematically covering the area concerned with triangles.\n\n\n5.3.2 Laguerre’s method\nLaguerre’s method is a root finding method tailored for polynomials and applies to complex polynomials and compex roots. We will look at the polynomial\n\\[\n  x^2 - 5.4\\ x^4 + 14.45\\ x^3 - 32.292\\ x^2 + 47.25\\ x - 26.46\n\\]\nthat has roots \\(\\pm \\sqrt{-5}\\), \\(2.1\\) (twofold), and \\(1.2\\).\np5 &lt;- c(1.0, -5.4, 14.45, -32.292, 47.25, -26.46)\n\nlaguerre(p, 1)   #=&gt; 1.2\nlaguerre(p, 2)   #=&gt; 2.099987     (should be 2.1)\nlaguerre(p, 2i)  #=&gt; 0+2.236068i  (+- 2.2361i, i.e sqrt(-5))\nComputations are carried out in complex arithmetic, and it is possible to obtain a complex root even if the starting estimate is real."
  },
  {
    "objectID": "rootfinding.html#polynomial-roots",
    "href": "rootfinding.html#polynomial-roots",
    "title": "5  Root Finding",
    "section": "5.4 Polynomial roots",
    "text": "5.4 Polynomial roots\nBase R has the function polyroot that implements the Jenkins-Traub algorithm. It finds proper roots on by one and decreases the order of the polynomial by deflating it (i.e., dividing by a root term).\nThen there is package ‘polynomF’ for handling of polynomials. solve.polynom(p, q) will solve polynomial equations \\(p(x) = q(x)\\) where p and q have to be defined as of class polynom.\n\n5.4.1 Roots as eigenvalues\nIn ‘pracma’ polynomials are represented as vectors of their coefficients, starting with the highest monomial (see the chapter on polynomials in the handbook). Thus, the vector c(1,2,3,4,5) will represent the polynomial \\(x^4 + 2x^3 + 3x^2 + 4x + 5\\).\nOne standard approach to find all roots of a polynomial is to calculate the eigenvalues of the so-called companion matrix. In general this works quite well and is accurate enough for most applications. In ‘pracma’ this is implemented as function roots.\nAs an example find the roots of \\((x+2)(x+1)(x-1)(x-2)\\) (which are -2, -1, 1, 2, obviously).\n\np = Poly(c(-2,-1,1, 2))     # x^5 - 5 x^3 + 4\nroots(p)\n\n[1] -2  2 -1  1\n\n\nroots will also solve polynomials with complex coefficients, for example here we find solutions to \\(x^2 - i = 0\\):\n\np = c(1, 0, -1i)\nroots(p)\n\n[1]  0.7071068+0.7071068i -0.7071068-0.7071068i\n\n\nIn general the results of polyroot and roots are identical. But there are types of polynomials for which the results (of both) are unsatisfactory, for instance the “Wilkinson polynomial”.\n\n\n5.4.2 Multiple roots\nAnother problem are multiple roots. If several multiple roots or roots with higher orders are present, the results become unbearable (for polyroot and roots). In this case the polyroots function attempts to refine the results of roots.\n\np &lt;- c(1,0,-4,0,6,0,-4,0,1,0,0)   #  x^10 - 4x^8 + 6x^6 - 4x^4 + x^2\nroots(p)\n\n [1]  0.0000000+0.0000000i  0.0000000+0.0000000i  1.0000783+0.0000000i\n [4] -1.0000633+0.0000633i -1.0000633-0.0000633i  1.0000000+0.0000783i\n [7]  1.0000000-0.0000783i -0.9999367+0.0000633i -0.9999367-0.0000633i\n[10]  0.9999217+0.0000000i\n\n\nThese are not very accurate roots. You could try to refine one by one, or:\n\npolyroots(p)\n\n  root mult\n1    0    2\n2    1    4\n3   -1    4\n\n\nThe function rootsmult attempts to determine the order of possible roots. As this computation is problematic in double precision, it is only really applicable to integer roots.\n\nrootsmult(p, 1.0)\n\n[1] 4\n\n\nIt will give a warning if that is x value not a root (in double precision).\n\n\n5.4.3 A degree 100 example\nWe look at an example that has been discussed on R-help a long time ago. Find the root of the following polynomial near \\(x = 2\\):\n\\[\n  x^{100}-2 x^{99}+10 x^{50}+6 x-4000\n\\]\nUsing roots will display a beautiful “circle of roots” with on outlier at or near 2.0.\n\np = numeric(101)\np[1] &lt;- 1; p[2] &lt;- -2; p[51] &lt;- 10; p[100] &lt;- 6; p[101] &lt;- -4000\n\nplot(roots(p), col = 4, pch = 'x', asp = 1,\n     main = \"Roots of a polynomial of order 100\")\ngrid()\n\n\n\n\nThere appear to be real roots near -1.0, 1.0 and at \\(x = 2.0\\). Can we verify this? First, take the approximation calculated by roots and apply Newton’s rule to find a good double-precision approximation.\n\nx0 &lt;- Re(roots(p)[1])\nx1 &lt;- x0 - polyval(p, x0)/polyval(polyder(p), x0)\nprint(x0, digits = 16)\n\n[1] 1.999999999999979\n\nprint(x1, digits = 16)\n\n[1] 1.999999999999982\n\n\nLaguerre’s method applied at -1.075 gives us the same value as roots(p)[100]. (Applied at 1.0 it will return the other root near 2.0.)\n\nx1 &lt;- laguerre(p, -1.075)\nprint(x1, digits = 10)\n\n[1] -1.074126672\n\n\nTo see if there is a real root near +1.0, we enclose it with Muller’s method.\n\nfp &lt;- function(x) polyval(p, x)\nmuller(fp, 1.0, 1.05, 1.1)$root\n\n[1] 1.074658+0.172133i\n\n\nSo there is no real root around 1.0, the two roots found are the only real roots. (This could be verified with Steiner’s rule.)\nNOTE: None of the root finding routines mentioned above will come close to this result in accuracy (except, maybe, bisect). It is suggested to always handle roots of polynomials specially."
  },
  {
    "objectID": "rootfinding.html#multivariate-function-roots",
    "href": "rootfinding.html#multivariate-function-roots",
    "title": "5  Root Finding",
    "section": "5.5 Multivariate function roots",
    "text": "5.5 Multivariate function roots\nThere are no routines in Base R for determining roots of function \\(F: \\mathbb{R}^m \\to \\mathbb{R}^n\\) for \\(m, n \\ge 2\\), that is of “systems of nonlinear equations”. In textbooks two approaches are mentioned Gauss-Newton and Broyden, a variant thereof.\nThe package ‘nleqslv’ provides a careful implementation of these with many options for the function nleqslv. The implementation as multiroot in package ‘rootSolve’ is also very good. It is true that Gauss-Newton approaches will often not find true solutions for higher-dimensional problems.\n\n5.5.1 Gauss-Newton, Broyden\nIn ‘pracma’, there is fsolve that applies Gauss-Newton for systems \\(F: \\mathbb{R}^m \\to \\mathbb{R}^n\\) and Broyden in case \\(m = n\\). Please note that for Gauss-Newton the same reservations are valid as for Newton in the one-dimensional case (i.e., the starting point has to be chosen carefully).\nWe solve the following complex equation\n\\[\n  \\sin^2(z) + \\sqrt{z} - \\log(z) = 0\n\\]\nby splitting in real and imaginary parts and constructing a function F from \\(\\mathbb{R}^2\\) to \\(\\mathbb{R}^2\\).\n\nF &lt;- function(p) {\n    z  &lt;- p[1] + p[2]*1i\n    fz &lt;- sin(z)^2 + sqrt(z) - log(z)\n    return( c(Re(fz), Im(fz)) )\n}\n\nfsolve(F, c(1, 1))\n\n$x\n[1] 0.2555197 0.8948303\n\n$fval\n[1] -4.849507e-10 -5.435474e-10\n\n\nthat is, \\(0.2555197 + 0.8948303i\\) is a solution (there are more). Calling gaussNewton(c(1, 1), F) or broyden(F, c(1, 1)) directly would give us more information about accuracy and number of iterations.\n\n\n5.5.2 Newton for systems\nThere is also the newtonsys routine that applies the pure Newton method to systems of nonlinear function with \\(m = n\\); it may be faster, but less stable and reliable.\n\nnewtonsys(F, c(1, 1))\n\n$zero\n[1] 0.2555197 0.8948303\n\n$fnorm\n[1] 4.236705e-16\n\n$niter\n[1] 8\n\n\nAll these routines can be provided with the Jacobian as an input argument. This is only useful if an exact, i.e. symbolic, Jacobian ist known."
  },
  {
    "objectID": "rootfinding.html#appendix-test-functions",
    "href": "rootfinding.html#appendix-test-functions",
    "title": "5  Root Finding",
    "section": "5.6 Appendix: Test functions",
    "text": "5.6 Appendix: Test functions\nf1  &lt;- function(x)                          # [0, 1.2],       0.399 422 2917\n            x^2 * (x^2/3 + sqrt(2)*sin(x)) - sqrt(3)/18\nf2  &lt;- function(x) 11*x^11 - 1              # [0.4, 1.6],     0.804 133 0975\nf3  &lt;- function(x) 35*x^35 - 1              # [-0.5, 1.9],    0.903 407 6632\nf4  &lt;- function(x)                          # [-0.5, 0.7],    0.077 014 24135\n            2*(x*exp(-9) - exp(-9*x)) + 1\nf5  &lt;- function(x) x^2 - (1 - x)^9          # [-1.4, 1],      0.259 204 4937\nf6  &lt;- function(x) (x-1)*exp(-9*x) + x^9    # [-0.8, 1.6],    0.536 741 6626\nf7  &lt;- function(x) x^2 + sin(x/9) - 1/4     # [-0.5, 1.9],    0.4475417621\nf8  &lt;- function(x) 1/8 * (9 - 1/x)          # [0.001, 1.201], 0.111 111 1111\nf9  &lt;- function(x) tan(x) - x - 0.0463025   # [-0.9, 1.5],    0.500 000 0340\nf10 &lt;- function(x)                          # [0.4, 1],       0.679 808 9215\n            x^2 + x*sin(sqrt(75)*x) - 0.2\nf11 &lt;- function(x) x^9 + 0.0001             # [-1.2, 0],     -0.359 381 3664\nf12 &lt;- function(x)                          # [1, 3.4],       1.648 721 27070\n            log(x) + x^2/(2*exp(1)) - 2 * x/sqrt(exp(1)) + 1"
  },
  {
    "objectID": "intro.html#details",
    "href": "intro.html#details",
    "title": "1  Introduction",
    "section": "1.1 Details",
    "text": "1.1 Details\nThe package encompasses functions from all areas of numerical analysis, for example:\n\nRoot finding and minimization of univariate functions,\ne.g. Newton-Raphson, Brent-Dekker, Fibonacci or `golden ratio’ search.\nHandling polynomials, including roots and polynomial fitting,\ne.g. Laguerre’s and Muller’s methods.\nInterpolation and function approximation,\nbarycentric Lagrange interpolation, Pade and rational interpolation, Chebyshev or trigonometric approximation.\nSome special functions,\ne.g. Fresnel integrals, Riemann’s Zeta or the complex Gamma function, and Lambert’s W computed iteratively through Newton’s method.\nSpecial matrices, e.g. Hankel, Rosser, Wilkinson\nNumerical differentiation and integration,\nRichardson approach and ``complex step’’ derivatives, adaptive Simpson and Lobatto integration and adaptive Gauss-Kronrod quadrature.\nSolvers for ordinary differential equations and systems,\nEuler-Heun, classical Runge-Kutta, ode23, or predictor-corrector method such as the Adams-Bashford-Moulton.\nSome functions from number theory,\nsuch as primes and prime factorization, extended Euclidean algorithm.\nSorting routines, e.g. recursive quickstep.\nSeveral functions for string manipulation and regular search, all wrapped and named similar to their Matlab analogues."
  },
  {
    "objectID": "intro.html#goals",
    "href": "intro.html#goals",
    "title": "1  Introduction",
    "section": "1.2 Goals",
    "text": "1.2 Goals\nIt serves two main goals:\n\nCollecting R scripts that can be demonstrated in courses on Numerical Analysis or Scientific Computing using R/S as the chosen programming language.\nWrapping functions with appropriate Matlab names to simplify porting programs from Matlab or Octave to R.\nProviding an environment in which R can be used as a full-blown numerical computing system.\n\nBesides that, many of these functions could be called in R applications as they do not have comparable counterparts in other R packages (at least at this moment, as far as I know).\nAll referenced books have been utilized in one way or another. Web links have been provided where reasonable."
  },
  {
    "objectID": "intro.html#emulated-matlab-functions",
    "href": "intro.html#emulated-matlab-functions",
    "title": "1  Introduction",
    "section": "1.3 Emulated MATLAB Functions",
    "text": "1.3 Emulated MATLAB Functions\nThe following 220 functions are emulations of correspondingly named Matlab functions and bear the same signature as their Matlab cousins if possible:\naccumarray, acosd, acot, acotd, acoth, acsc, acscd, acsch, and, angle, ans,\narrayfun, asec, asecd, asech, asind, atand, atan2d,  \nbeep, bernoulli, blank, blkdiag, bsxfun,  \ncart2pol, cart2sph, cd, ceil, circshift, clear, compan, cond, conv,  \ncosd, cot, cotd, coth, cross, csc, cscd, csch, cumtrapz,  \ndblquad, deblank, deconv, deg2rad, detrend, deval, disp, dot,  \neig, eigint, ellipj, ellipke, eps, erf, erfc, erfcinv, erfcx, erfi, erfinv,  \nerrorbar, expint, expm, eye, ezcontour, ezmesh, ezplot, ezpolar, ezsurf,  \nfact, fftshift, figure, findpeaks, findstr, flipdim, fliplr, flipud,  \nfminbnd, fminsearch, fplot, fprintf, fsolve, fzero,  \ngammainc, gcd, geomean, gmres, gradient,  \nhadamard, hankel, harmmean, hilb, histc, humps, hypot,  \nidivide, ifft, ifftshift, inpolygon, integral, integral2, integral3,  \ninterp1, interp2, inv, isempty, isprime,  \nkron,  \nlegendre, linprog, linspace, loglog, logm, logseq, logspace, lsqcurvefit,  \nlsqlin, lsqnonlin, lsqnonneg, lu,  \nmagic, meshgrid, mkpp, mldivide, mod, mrdivide,  \nnchoosek, ndims, nextpow2, nnz, normest, nthroot, null, num2str, numel,  \node23, ode23s, ones, or, orth,  \npascal, pchip, pdist, pdist2, peaks, perms, piecewise, pinv, plotyy,  \npol2cart, polar, polyfit, polyint, polylog, polyval, pow2, ppval,  \nprimes, psi, pwd,  \nquad, quad2d, quadgk, quadl, quadprog, quadv, quiver,  \nrad2deg, randi, randn, randsample, rat, rats, regexp, regexpi,  \nregexpreg, rem, repmat, roots, rosser, rot90, rref, runge,  \nsec, secd, sech, semilogx, semilogy, sinc, sind, size, sortrows, sph2cart,  \nsqrtm, squareform, std, str2num, strcat, strcmp, strcmpi,  \nstrfind, strfindi, strjust, subspace,  \ntand, tic, toc, trapz, tril, trimmean, triplequad, triu,  \nvander, vectorfield, ver,  \nwhat, who, whos, wilkinson,  \nzeros, zeta\nThe following Matlab function names have been capitalized in `pracma’ to avoid shadowing functions from R base or one of its recommended packages (on request of Bill Venables and because of Brian Ripley’s CRAN policies):\nDiag, factos, finds, Fix, Imag, Lcm, Mode, Norm, nullspace (&lt;- null),\nPoly, Rank, Real, Reshape, strRep, strTrim, Toeplitz, Trace, uniq (&lt;- unique).\nTo use ans instead of ans() – as is common practice in Matlab – type (and similar for other Matlab commands):\nmakeActiveBinding(\"ans\", function() .Last.value, .GlobalEnv)\nmakeActiveBinding(\"who\", who(), .GlobalEnv)"
  },
  {
    "objectID": "intro.html#references",
    "href": "intro.html#references",
    "title": "1  Introduction",
    "section": "1.5 References",
    "text": "1.5 References\nAbramowitz, M., and I. A. Stegun (1972). Handbook of Mathematical Functions (with Formulas, Graphs, and Mathematical Tables). Dover, New York. http://www.nr.com/aands/.\nArndt, J. (2010). Matters Computational: Ideas, Algorithms, Source Code. Springer-Verlag, Berlin Heidelberg Dordrecht. FXT: a library of algorithms: http://www.jjj.de/fxt/.\nCormen, Th. H., Ch. E. Leiserson, and R. L. Rivest (2009). Introduction to Algorithms. Third Edition, The MIT Press, Cambridge, MA.\nEncyclopedia of Mathematics (2012). Editor-in-Chief: Ulf Rehmann. http://www.encyclopediaofmath.org/.\nGautschi, W. (1997). Numerical Analysis: An Introduction. Birkhaeuser, Boston.\nGentle, J. E. (2009). Computational Statistics. Springer Science+Business Media LCC, New York.\nHazewinkel, M., Editor (2002). Encyclopaedia of Mathematics. Springer-Verlag, Berlin Heidelberg New York. http://eom.springer.de/.\nMathWorld.com (2011). Matlab Central: http://www.mathworks.com/matlabcentral/. Mathtools.net: http://www.mathtools.net/.\nNIST: National Institute of Standards and Technology. Olver, F. W. J., et al. (2010). NIST Handbook of Mathematical Functions. Cambridge University Press. Internet: NIST Digital Library of Mathematical Functions, http://dlmf.nist.gov/; Dictionary of Algorithms and Data Structures, http://www.nist.gov/; Guide to Available Mathematical Software, http://gams.nist.gov/\nPress, W. H., S. A. Teukolsky, W. T Vetterling, and B. P. Flannery (2007). Numerical Recipes: The Art of Numerical Computing. Third Edition, incl. Numerical Recipes Software, Cambridge University Press, New York. http://www.nrbook.com/a/bookcpdf.php [chapters], or http://apps.nrbook.com/c/index.html [pages].\nQuarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics. Second Edition, Springer-Verlag, Berlin Heidelberg.\nSkiena, St. S. (2008). The Algorithm Design Manual. Second Edition, Springer-Verlag, London. The Stony Brook Algorithm Repository: http://www.cs.sunysb.edu/~algorith/.\nStoer, J., and R. Bulirsch (2002). Introduction to Numerical Analysis. Third Edition, Springer-Verlag, New York.\nStrang, G. (2007). Computational Science and Engineering. Wellesley-Cambridge Press. Matlab Codes: http://www-math.mit.edu/cse/\nWeisstein, E. W. (2003). CRC Concise Encyclopedia of Mathematics. Second Edition, Chapman & Hall/CRC Press. Wolfram MathWorld: http://mathworld.wolfram.com/.\nZhang, S., and J. Jin (1996). Computation of Special Functions. John Wiley & Sons."
  },
  {
    "objectID": "intro.html#note",
    "href": "intro.html#note",
    "title": "1  Introduction",
    "section": "1.4 Note",
    "text": "1.4 Note\nThe R package `matlab’ contains some of the basic routines from Matlab, but unfortunately not any of the higher math routines."
  },
  {
    "objectID": "rootfinding.html#contents",
    "href": "rootfinding.html#contents",
    "title": "5  Root Finding",
    "section": "Contents",
    "text": "Contents\n\nUnivariate roots\nBrent-Dekker; Ridders’ method; bisection, secant and regula-falsi; Newton-Raphson; and Haley\nSpecial aspects\nQuadratic roots; find all roots; high-accuracy roots; roots as fixed points\nComplex roots\nMuller’s and Laguerre’s method\nPolynomial roots\nRoots as eigenvalues; multiple roots; degree 100 example\nMultivariate function roots\nGauss-Newton; Broyden; Newton for systems\nAppendix: Test functions"
  },
  {
    "objectID": "derivatives.html",
    "href": "derivatives.html",
    "title": "3  Numerical Derivatives",
    "section": "",
    "text": "To be done."
  },
  {
    "objectID": "integrals.html",
    "href": "integrals.html",
    "title": "4  Numerical Integation",
    "section": "",
    "text": "To be done."
  }
]